{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPIzxFDzGHGFd1Irl7vrVPO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexander-toschev/mbzuai-course/blob/main/Exersice/Exersice1_DataAugmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exercise Description: Image Augmentation and Neural Network Training**\n",
        "\n",
        "#### **Objective**\n",
        "In this exercise, students will:\n",
        "1. **Implement data augmentation** techniques to improve dataset variability.\n",
        "2. **Extend the dataset** by applying augmentations to a subset of images.\n",
        "3. **Construct and train a Convolutional Neural Network (CNN)** for image classification.\n",
        "4. **Evaluate model performance** before and after augmentation.\n",
        "5. **Use automated testing (`unittest`)** to validate correctness.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tasks to be Completed**\n",
        "#### **1. Implement the `apply_augmentation(image)` function**\n",
        "- **Purpose**: Modify an input image using augmentation techniques.\n",
        "- **Requirements**:\n",
        "  - Adjust brightness and contrast.\n",
        "  - Add Gaussian noise.\n",
        "  - Apply horizontal flipping.\n",
        "  - Ensure the output image maintains the same shape.\n",
        "\n",
        "#### **2. Implement the `augment_and_extend_dataset(dataset_path)` function**\n",
        "- **Purpose**: Select 10% of the dataset, apply augmentation, and save new images with the prefix `aug_`.\n",
        "- **Requirements**:\n",
        "  - Select **10% of images from each category** (cats, dogs).\n",
        "  - Apply `apply_augmentation(image)`.\n",
        "  - Save augmented images with **a modified filename (`aug_` prefix)**.\n",
        "\n",
        "#### **3. Implement `createModel()`**\n",
        "- **Purpose**: Build a Convolutional Neural Network (CNN) for binary image classification.\n",
        "- **Architecture**:\n",
        "  - **Convolutional layers** (Extract features).\n",
        "  - **Pooling layers** (Reduce dimensionality).\n",
        "  - **Flattening layer** (Prepare for classification).\n",
        "  - **Fully connected dense layers** (Make predictions).\n",
        "  - **Sigmoid activation in the output layer** (Binary classification).\n",
        "\n",
        "---\n",
        "\n",
        "### **Evaluation Criteria**\n",
        "Your solution will be **automatically graded** using `unittest`. The tests will check:\n",
        "âœ… If **augmented images differ** from the original images.  \n",
        "âœ… If **new images are successfully added** after augmentation.  \n",
        "âœ… If the **CNN model structure** matches the expected architecture.\n",
        "\n",
        "---\n",
        "\n",
        "### **Bonus Challenges**\n",
        "ðŸš€ **Bonus 1**: Improve augmentation techniques (e.g., rotation, zoom, cutout).  \n",
        "ðŸš€ **Bonus 2**: Experiment with different CNN architectures to achieve better accuracy.  \n",
        "\n",
        "Once completed, **run the unit tests** at the end of the notebook to check your implementation!"
      ],
      "metadata": {
        "id": "pvpPXnAWB8L8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0yynK0nYzMA",
        "outputId": "0971560e-a45b-4b99-84c4-77d15354d9f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on Original Dataset...\n",
            "Found 4024 images belonging to 2 classes.\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - loss: 3.9486 - precision: 0.5464\n",
            "Epoch 2/6\n",
            "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - loss: 0.5868 - precision: 0.7502\n",
            "Epoch 3/6\n",
            "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - loss: 0.3393 - precision: 0.8820\n",
            "Epoch 4/6\n",
            "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - loss: 0.1931 - precision: 0.9566\n",
            "Epoch 5/6\n",
            "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - loss: 0.0925 - precision: 0.9810\n",
            "Epoch 6/6\n",
            "\u001b[1m126/126\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - loss: 0.0729 - precision: 0.9931\n",
            "Training on Augmented Dataset...\n",
            "Found 4223 images belonging to 2 classes.\n",
            "Epoch 1/6\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 66ms/step - loss: 3.1014 - precision: 0.5116\n",
            "Epoch 2/6\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - loss: 0.6268 - precision: 0.6681\n",
            "Epoch 3/6\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.5134 - precision: 0.7946\n",
            "Epoch 4/6\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.3668 - precision: 0.8699\n",
            "Epoch 5/6\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - loss: 0.2655 - precision: 0.9258\n",
            "Epoch 6/6\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - loss: 0.2055 - precision: 0.9399\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (Original Dataset): 0.9859\n",
            "Precision (Augmented Dataset): 0.9527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "./usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 2.489s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Score: 50/50\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.metrics import precision_score\n",
        "import random\n",
        "import unittest\n",
        "\n",
        "# Download and load dataset\n",
        "def download_dataset():\n",
        "    dataset_url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
        "    response = requests.get(dataset_url)\n",
        "    with open(\"dataset.zip\", \"wb\") as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "    with ZipFile(\"dataset.zip\", \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"dataset\")\n",
        "\n",
        "    return \"dataset/cats_and_dogs_filtered/train\"\n",
        "\n",
        "# Load dataset\n",
        "dataset_path = download_dataset()\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Function to apply augmentation\n",
        "def apply_augmentation(image):\n",
        "    \"\"\"\n",
        "    Applies a set of augmentations to the given image.\n",
        "    Augmentations include brightness contrast adjustment, noise addition, and flipping.\n",
        "    Use RandomBrightnessContrast, GaussNoise and HorizontalFlip\n",
        "    \"\"\"\n",
        "    transform = A.Compose([\n",
        "        # 3 lines of code\n",
        "\n",
        "\n",
        "\n",
        "        # end\n",
        "    ])\n",
        "    return transform(image=image)['image']\n",
        "\n",
        "# Function to augment 10% of dataset and add to existing dataset\n",
        "def augment_and_extend_dataset(dataset_path):\n",
        "    \"\"\"\n",
        "    Selects 10% of images from each category, applies augmentation,\n",
        "    and saves the augmented images with a prefix `aug_`.\n",
        "    :param dataset_path: Path to the dataset directory.\n",
        "    \"\"\"\n",
        "    categories = [\"cats\", \"dogs\"]\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "        images = os.listdir(category_path)\n",
        "        # 1 line of code, select sample size\n",
        "        sample_size =\n",
        "        selected_images = random.sample(images, sample_size)\n",
        "\n",
        "        for img_name in selected_images:\n",
        "            img_path = os.path.join(category_path, img_name)\n",
        "            image = load_image(img_path)\n",
        "            # 1 line of code apply augmentation function\n",
        "\n",
        "            # end\n",
        "            augmented_image = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            # 2 lines of code generate name and folder path\n",
        "            new_img_name =\n",
        "            new_img_path =\n",
        "            # end\n",
        "            cv2.imwrite(new_img_path, augmented_image)\n",
        "\n",
        "def createModel():\n",
        "    model = Sequential([\n",
        "        # create CNN model 5 lines\n",
        "        # Conv2D First convolutional layer (32, (3,3)) Input shape (150, 150, 3), MaxPooling First pooling layer , Flatten Flattening layer, Dense Fully connected hidden layer (128)\n",
        "        # with relu and Dense with sigmoid with binary classification\n",
        "\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Train a simple CNN model\n",
        "def train_model(train_data):\n",
        "    model = createModel()\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['precision'])\n",
        "    model.fit(train_data, epochs=6, verbose=1)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Prepare dataset for training\n",
        "def prepare_dataset(dataset_path):\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "    return datagen.flow_from_directory(dataset_path, target_size=(150, 150), batch_size=32, class_mode='binary')\n",
        "\n",
        "# Train model on original dataset\n",
        "print(\"Training on Original Dataset...\")\n",
        "train_data = prepare_dataset(dataset_path)\n",
        "model = train_model(train_data)\n",
        "\n",
        "# Apply augmentation to 10% of dataset\n",
        "augment_and_extend_dataset(dataset_path)\n",
        "\n",
        "# Train model on augmented dataset\n",
        "print(\"Training on Augmented Dataset...\")\n",
        "train_data_aug = prepare_dataset(dataset_path)\n",
        "model_aug = train_model(train_data_aug)\n",
        "\n",
        "# Display comparison\n",
        "def compare_models(model1, model2, dataset1, dataset2):\n",
        "    y_true, y_pred1, y_pred2 = [], [], []\n",
        "    for _ in range(10):\n",
        "        batch_x, batch_y = next( dataset1)\n",
        "        preds1 = (model1.predict(batch_x) > 0.5).astype(int)\n",
        "        preds2 = (model2.predict(batch_x) > 0.5).astype(int)\n",
        "        y_true.extend(batch_y)\n",
        "        y_pred1.extend(preds1)\n",
        "        y_pred2.extend(preds2)\n",
        "\n",
        "    precision1 = precision_score(y_true, y_pred1)\n",
        "    precision2 = precision_score(y_true, y_pred2)\n",
        "\n",
        "    print(f\"Precision (Original Dataset): {precision1:.4f}\")\n",
        "    print(f\"Precision (Augmented Dataset): {precision2:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "compare_models(model, model_aug, train_data, train_data_aug)\n",
        "\n",
        "# Unit tests for augmentation and model structure\n",
        "class TestAugmentationAndModel(unittest.TestCase):\n",
        "\n",
        "    def test_apply_augmentation(self):\n",
        "        category_path = os.path.join(dataset_path, \"cats\")\n",
        "        images = sorted(os.listdir(category_path))\n",
        "\n",
        "        # Find an original and its augmented version\n",
        "        original_image_path = None\n",
        "        augmented_image_path = None\n",
        "        for img_name in images:\n",
        "            if img_name.startswith(\"aug_\"):\n",
        "                original_name = img_name.replace(\"aug_\", \"\")\n",
        "                if original_name in images:\n",
        "                    original_image_path = os.path.join(category_path, original_name)\n",
        "                    augmented_image_path = os.path.join(category_path, img_name)\n",
        "                    break\n",
        "\n",
        "        if original_image_path is None or augmented_image_path is None:\n",
        "            self.skipTest(\"No matching original and augmented images found\")\n",
        "\n",
        "        original_image = load_image(original_image_path)\n",
        "        augmented_image = load_image(augmented_image_path)\n",
        "\n",
        "        diff = np.mean(np.abs(original_image.astype(np.float32) - augmented_image.astype(np.float32)))\n",
        "        self.assertGreater(diff, 0.01, \"Augmented image is too similar to the original, augmentation may not be applied correctly.\")\n",
        "        global score\n",
        "        score+=20\n",
        "\n",
        "    def test_augment_and_extend_dataset(self):\n",
        "        initial_image_count = len(os.listdir(os.path.join(dataset_path, \"cats\")))\n",
        "        augment_and_extend_dataset(dataset_path)\n",
        "        new_image_count = len(os.listdir(os.path.join(dataset_path, \"cats\")))\n",
        "        self.assertGreater(new_image_count, initial_image_count, \"Dataset augmentation did not add new images.\")\n",
        "        global score\n",
        "        score+=20\n",
        "\n",
        "    def test_model_structure(self):\n",
        "        model = createModel()\n",
        "        self.assertEqual(len(model.layers), 5, \"Incorrect number of layers in the model.\")\n",
        "        self.assertIsInstance(model.layers[0], Conv2D, \"First layer should be a Conv2D layer.\")\n",
        "        self.assertIsInstance(model.layers[-1], Dense, \"Last layer should be a Dense layer.\")\n",
        "        global score\n",
        "        score+=10\n",
        "\n",
        "# Run unit tests\n",
        "if __name__ == \"__main__\":\n",
        "    score = 0\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
        "    print(f\"Student Score: {score}/50\")"
      ]
    }
  ]
}